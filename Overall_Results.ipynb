{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Results\n",
    "- This file takes the best models for each algorithm implementation and compares them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "X_test = test_data['X_test'].tolist()\n",
    "y_test = test_data['y_test'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m tree_pred \u001b[38;5;241m=\u001b[39m decision_tree()\n\u001b[1;32m      6\u001b[0m mlp_pred \u001b[38;5;241m=\u001b[39m mlp()\n\u001b[0;32m----> 7\u001b[0m lr_pred, lr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m nb_pred \u001b[38;5;241m=\u001b[39m naive_bayes()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# All predictions on a single data structure\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI-Term-Project/all_models.py:37\u001b[0m, in \u001b[0;36mlogistic_regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m y_test_raw \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Format the X values into lists.\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m X_train_raw \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     38\u001b[0m     ast\u001b[38;5;241m.\u001b[39mliteral_eval(item) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m X_train_raw\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     41\u001b[0m X_test_raw \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     ast\u001b[38;5;241m.\u001b[39mliteral_eval(item) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m X_test_raw\n\u001b[1;32m     43\u001b[0m ]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Utilize the Bag of Words approach using a CountVectorizer.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Convert the train and test data into strings for the CountVectorizer.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI-Term-Project/all_models.py:38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m y_test_raw \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Format the X values into lists.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m X_train_raw \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m X_train_raw\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     41\u001b[0m X_test_raw \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     ast\u001b[38;5;241m.\u001b[39mliteral_eval(item) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m X_test_raw\n\u001b[1;32m     43\u001b[0m ]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Utilize the Bag of Words approach using a CountVectorizer.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Convert the train and test data into strings for the CountVectorizer.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ast.py:62\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mSafely evaluate an expression node or a string containing a Python\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mexpression.  The string or node provided may only consist of the following\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mPython literal structures: strings, bytes, numbers, tuples, lists, dicts,\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03msets, booleans, and None.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, Expression):\n\u001b[1;32m     64\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m node_or_string\u001b[38;5;241m.\u001b[39mbody\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ast.py:50\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, filename, mode, type_comments, feature_version)\u001b[0m\n\u001b[1;32m     48\u001b[0m     feature_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Else it should be an int giving the minor version for 3.x.\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m               \u001b[49m\u001b[43m_feature_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_version\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from all_models import mlp, naive_bayes, logistic_regression, svm, decision_tree\n",
    "\n",
    "# Load the best model predictions\n",
    "svm_pred = svm()\n",
    "tree_pred = decision_tree()\n",
    "mlp_pred = mlp()\n",
    "lr_pred, lr_loss = logistic_regression()\n",
    "nb_pred = naive_bayes()\n",
    "\n",
    "\n",
    "# All predictions on a single data structure\n",
    "predictions = { \n",
    "               'SVM': svm_pred,\n",
    "               'Decision Tree': tree_pred,\n",
    "               'MLP': mlp_pred,\n",
    "               'Logistic Regression': lr_pred,\n",
    "               'Naive Bayes': nb_pred\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Results\n",
    "- Classification report for each model\n",
    "- Consolidated Graph with Accuracy F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score\n",
    "\n",
    "# Calculate the accuracy for each\n",
    "models_accuracy = { \n",
    "               'SVM': accuracy_score(y_test, svm_pred),\n",
    "               'Decision Tree': accuracy_score(y_test,tree_pred),\n",
    "               'MLP': accuracy_score(y_test,mlp_pred),\n",
    "               'Logistic Regression': accuracy_score(y_test,lr_pred),\n",
    "               'Naive Bayes': accuracy_score(y_test,nb_pred)\n",
    "}\n",
    "\n",
    "models_f1score = { \n",
    "               'SVM': f1_score(y_test, svm_pred),\n",
    "               'Decision Tree': f1_score(y_test,tree_pred),\n",
    "               'MLP': f1_score(y_test,mlp_pred),\n",
    "               'Logistic Regression': f1_score(y_test,lr_pred),\n",
    "                'Naive Bayes': f1_score(y_test,nb_pred)\n",
    "}\n",
    "\n",
    "# Prin the Classification Report \n",
    "for key, value in predictions.items():\n",
    "    print(f'Model {key}: ')\n",
    "    print(f'Classification Report: \\n {classification_report(y_test, value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "# Random Baseline Calculated by picking a random class\n",
    "random_baseline = 0.1458\n",
    "\n",
    "# model_names = ['MLP', 'Decision Tree', 'Logistic Regression', 'SVM', 'Naive Bayes']\n",
    "# accuracies = \n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models_accuracy.keys(), models_accuracy.values(), color=['green', 'blue', 'red', 'orange', 'purple'])\n",
    "\n",
    "# Add the random baseline\n",
    "plt.axhline(y=random_baseline, color='grey', linestyle='--', linewidth=1, label='Random Baseline')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Adding data labels\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval - 0.1, f'{yval:.4f}', ha='center', va='top', color='white')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracies with Random Baseline')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
